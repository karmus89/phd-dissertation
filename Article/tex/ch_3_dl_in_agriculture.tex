Deep learning refers to models composed of multiple layers. Generally, a model is viewed as deep if it has at least an input layer, one hidden layer and an output layer. The term neural, on the other hand, refers to the fact that originally the operation principle of artificial neural networks was taken from that of the brain, containing neurons as its basic building blocks. As discussed by Tantalaki et al., the increasing volume of agricultural data from multiple sources calls for modelling techniques with an ability to perform automatic feature weighing and selection with complex and heterogeneous data \cite{Tantalaki2019}. Being non-linear and data-based, deep learning models have been recently more and more the modelling technique of choice in several application contexts.

The intention of the preceding chapter was to provide a broad overview of the data sources and their prevalence in the realm of agricultural data-based modelling. The goal of this chapter is to give the reader an overview on the tasks and problems in smart farming where deep learning structures have been successfully used and to provide enough background to understand the selection of particular models in the studies included in this thesis as well as their application contexts. With the publications of this dissertation focusing on spatial data, the discussion will be limited to spatial and spatiotemporal applications. In addition to considering recent relevant reviews, this chapter will also delve more into indvidual studies in terms of methods, application contexts and attained performance. 

Thus, this chapter is constructed as follows. The first section is dedicated to reviewing studies focusing on deep learning and smart farming in general. The focus of the section is to build a contextual foundation of how deep learning has been recently utilized in agricultural context. After that, the following section and its subsections are dedicated to distinct model architectures. For each architecture, brief introduction is given on the operating principles. These introductions are then followed by reviews of distinct studies to provide the reader with an understanding of the possibilities and possible limitations of each architecture.

\section{Deep learning in agriculture}
\label{sec:dl-in-agri-review}

The use of deep learning techniques in agriculture and agriculture-related remote sensing applications has gained a lot of attention recently. According to several reviews, the number of deep learning studies in the mentioned context has increased dramatically since 2015. According to a review of deep learning techniques in agriculture by Kamilaris and Prenafeta-Bold{\'{u}}, the number of deep learning related studies in the context of agriculture were virtually non-existent prior to year 2015 \cite{Kamilaris2018a}. In a review of crop studies focusing on crop yield prediction using machine learning, the yearly distribution of studies is heavily focused on past two years \cite{VanKlompenburg2020}. Similar observation is made also in \cite{Unal2020}, where 76 out of 120 reviewed papers were published in 2019.

In a review conducted by Kamilaris and Prenafeta-Bold{\'{u}}, 40 deep learning and agriculture related studies were examined \cite{Kamilaris2018a}. The authors identified 16 distinct applications for deep learning, including crop or weed detection (8), plant or crop type classification (4), plant recognition (4), fruit counting (4) and crop yield estimation (2). Out of the selected studies, 30 studies utilized computer vision based algorithms in some form. These algorithms include various custom-defined and pre-trained convolutional neural networks (CNN). Other algorithms present in the studies include long short-term memory networks (LSTM), autoencoders and a hybrid CNN-LSTM. They observe that, in addition to performance increases attained with the use of deep learning techniques, the need to pre-engineer independent predictor features is mainly eliminated. The models are generally seen as performant, albeit the training times are observed to be generally higher than with traditional machine learning methods. The need of large data sets is seen as a considerable drawback. Another data-induced limitation is the training data set's limited expressiveness of the underlying data producing phenomenon. They conclude that with image-like data, deep learning offers performant and reliable modelling techniques.

Tantalaki et al. also discuss the role of neural networks and deep learning in their review of data-driven decision making in agriculture \cite{Tantalaki2019}. They attribute the increased use of deep learning techniques in agriculture partially to the models' ability to handle complex and non-linear agricultural problems. Their review is focused more on the developments of machine learning in the agricultural domain up until recent times. Neural network related techniques are separated to simpler artificial neural networks (ANN) and more complex image-based deep learning techniques. Out of 29 studies published between the years 1995 and 2018, they observe 15 studies utilizing ANNs and two deep learning related studies. ANNs have been utilized in crop, soil, weed, disease and weather related applications. Crop related studies, where both ANN and deep learning techniques were utilized, include yield estimation, type classification and feature estimation. Their general observation is that, with the developments in both data-based modelling techniques, IT infrastructure and data generation processes, deep learning is a prominent direction for data-based modelling. 

In a review focusing crop yield prediction using machine learning, van Klompenburg et al. found 50 related studies starting from 2008 \cite{VanKlompenburg2020}. Out of them, 30 studies utilized deep learning in some form. In those studies, a total of 33 various deep learning architectures were present. The architectures included CNN, LSTM and deep neural networks (DNN), with the CNN being the most common at 11 occurrences and the latter being present 7 times. Spatiotemporal architectures were also observed in some studies, including three-dimensional (3D) CNNs and CNN-LSTM hybrid models. In addition to deep learning models, several traditional machine learning algorithms were also used. These include linear regression and ensemble models, such as decision tree based random forest models. These models, as discussed by the authors, are often used as benchmark models for their deep learning counterparts.

\section{Performance metrics to evaluate yield prediction}
\label{sec:notes-on-metrics}

Crop-related deep learning research in agriculture is still a developing field which is starkly illustrated by the variety of performance metrics used across various studies. Kamilaris and Prenafeta-Bold{\'{u}} identified 16 different performance metrics in their review of 40 agriculture-related deep learning studies \cite{Kamilaris2018a}. The metric usage varies according to the modelling task (e.g. classification or regression) and formulation of the modelling problem (object recognition) \cite{Kamilaris2018b}.

Even with a specific task, i.e. crop yield prediction, at least 11 different performance metrics were observed \cite{VanKlompenburg2020}. The most popular metric with 40~\% usage according to \cite{VanKlompenburg2020} was the root mean square error (RMSE). While easy to calculate from the data, the interpretation of the metric is reliant on the knowledge of the value range and scale of true targets. This is true with other similar metrics, such as mean absolute error (MAE) and mean square error (MSE). Lower scores generally indicate better performance with these metrics. There are at least three key factors affecting the variability of the performance metrics. The first has to do with data preprocessing and, more specifically, data scaling where the use of absolute values produces different performance values from scaled values. The second factor is the environment with changes in annual weather patterns (local variability) and studies performed on similar crops but in different climates and soil characteristics (global variability). The third factor introducing variability in performance metrics are the crop varieties. While a modelling method would be comparable to an other method in terms of architecture and design, crop yields are different between different crop types (e.g. corn versus wheat). Xie and Yang identified at least 18 different types of crops while listing only a portion of all cereal crops \cite{Xie2020}. A selection of crop types and their average values across continents are given in Table~\ref{tab:iii-crop-yield-variation} to give a sense of scale for RMSE, MAE and MSE performance value interpretations.  

% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
\begin{table}[htb]
    \centering
    \scriptsize
    \caption{Average crop yields of 2018 by crop type and continent. Values obtained from \emph{Our world in data} service's crop yields data explorer \cite{owidcropyields} and are given in tonnes per hectare.}
    \label{tab:iii-crop-yield-variation}
    \vspace{0.3cm}
    \begin{tabular}{@{}lllllll@{}}

    \toprule
    \textbf{Crop} & \textbf{Africa} & \textbf{Asia} & \textbf{Australia} & \textbf{Europe} & \textbf{North America} & \textbf{South America} \\ \midrule
    Wheat         & 2.86            & 3.38          & 1.92               & 4.00            & 3.21                   & 2.98                   \\
    Barley        & 1.70            & 2.11          & 2.24               & 3.55            & 3.67                   & 3.80                   \\
    Rice          & 1.53            & 3.54          & 2.02               & 4.23            & 7.59                   & 4.45                   \\
    Maize         & 2.04            & 5.37          & 7.34               & 7.54            & 11.77                  & 5.26                   \\ \bottomrule
    \end{tabular}
\end{table}

One of the most popular yield prediction performance metrics is R$^2$, the coefficient of determination, which was used in 26~\% out of all crop yield regression studies reviewed in \cite{VanKlompenburg2020}. The general defition of the metric is 

\begin{equation}
    \begin{split}
    SS_{\text{tot}} & = \sum{(y_i-\mu_y)^2} \\
    SS_{\text{res}} & = \sum{(y_i-\hat{y}_i)^2} \\
    R^2 & = 1-\frac{SS_{\text{res}}}{SS_{\text{tot}}}
    \end{split}
\end{equation}

\noindent where $y_i$ is a target value, $\mu_y$ is the average of all target values and $\hat{y}_i$ is a prediction corresponding to a target value $y_i$. The metric represents the degree of variance explained in the target value given the input features in a regression model. R$^2$ values range typically from 0 to 1 with 1 indicating a perfectly fit model and a score of 0.5 is interpretable as model being able to account for 50~\% of variance w.r.t. the target values. Being proportion-based metric it is scale-invariant and thus produces comparable values as long as the compared data sets describe similar phenomena. 

Another utilized scale-invariant metric is the mean absolute percentage error (MAPE). It is defined as

\begin{equation}
    \text{MAPE}=\frac{ \sum^{n}_{i} \frac{|y_i-\hat{y}_i|}{y_i} }{n}
\end{equation}

\noindent and the value represents the average proportional deviation from true target values. As with RMSE, MSE and MAE, lower score indicates better performance. However, while MAPE is scale-invariant, the threshold of good performance depends on the data and requires domain knowledge for drawing deeper conclusions.


\section{Spatial and temporal deep learning architectures}
\label{sec:spatial-temporal-dl-review}

Data is one of the most crucial factors to take into account when selecting model architectures. Real-world spatial data requires architectures with capability to extract non-linear spatial features. Sequential data requires models capable of modelling change in the dimension of time, or change in general. Time series of spatial data require architectures with both of the aforementioned capabilities. 

Deep learning has been utilized in multiple smart farming related applications as shown in the previous section. In this section the focus is narrowed to discuss the model architectures relevant to spatial and spatiotemporal modelling. The publications selected for this dissertation mainly utilize spatial data. Publications [I-II] utilize UAV-based remote sensing data as spatial inputs. An input conforms to a distinct point in time. Publication [IV] utilizes time series of UAV-based spatial, i.e. spatiotemporal, data. While publication [V] makes use of temporally distinct spatial data, the distinction to publications [I-II] is in the use of multiple data sources. The only publication where spatial or spatiotemporal modelling is not utilized is [III], where the data, albeit initially spatial, is utilized in row-like manner.
 
\subsection{Convolutional neural networks}
\label{subsec:cnn-review}

Convolutional neural networks, often referred to as CNNs, have solidified their place in modeling tasks where the input data is either spatial or spatially representable \cite{Krizhevsky2017,Szegedy2015}. The main component of the model is the convolution operation, where a set of trainable kernels (or filters) is applied to the input data resulting in a set of spatial features describing the data. The model learns basic features in the first layers and composite features of these basic features at further layers \cite{Zeiler2014}. To help the model better learn these features, batch normalization can be applied to the inputs \cite{Ioffe2015}. The final output of a plain CNN is a set of feature maps. Depending on the use case, these can be either directly utilized or, for example, flattened and fed to a fully connected (FC) layer for regression or classification purposes. Traditional use case is to employ a CNN to extract spatial features from two-dimensional (2D) inputs. While spatial data normally contains multiple channels, the 2D kernels are applied to each channel, separately. CNNs can also be utilized in non-spatial manner when input data is tabular, i.e. row-like. The convolution operation is then applied one-dimensionally (1D), with the kernels operating on adjacent values in the row as defined by the kernel size.

As shown in multiple recent reviews of deep learning method utilization in agriculture and smart farming, CNNs constitute the majority of modelling approaches \cite{Kamilaris2018a,VanKlompenburg2020}. Kamilars and Prenafeta-Bold{\'{u}} conducted a review of studies utilizing CNNs in the domain of agriculture and published between the years 2014 and 2017 \cite{Kamilaris2018b}. They selected a total of 23 studies for closer inspection. They observe that CNNs were utilized mainly for classification tasks related to weed identification and fruit counting. Yield prediction is also observed as a major task. The studies divided evenly between using pre-trained models (12 studies) and custom-developed and trained architectures (11 studies). 

In a study of CNN-based yield response modelling to crop management activities in the US, Barbosa et al. developed four different CNN architectures to predict corn yield using medium-resolution multisource input data \cite{Barbosa2020}. The input data consisted of rates for nitrogen and seed, elevation maps, soil's electroconductivity and 3 m/px resolution commercial satellite data. The data used in the study was not multitemporal, meaning that each input represented a single point in time. Three of the models were based on 2D convolutions, differing on how the input data were introduced to the model and how the model features were combined to produce the final output. Last of the models was a 3D CNN, which will be discussed in later in Section~\ref{subsec:3d-cnn-review}. In the study the authors tested several traditional ML models and each of the CNN architectures. The best performance was attained with a CNN extracting spatial features from distinct spatial input channels. They reported best performance of 0.70 root mean squared error (RMSE). The RMSE is a proportion of the standard deviation of crop yields, translating to 1140 kilograms per hectare (kg/ha) on average when unscaled.

Tedesco-Oliveira et al. utilized several existing CNN-based architectures to classify cotton bolls and predict cotton yields from high-resolution images taken manually at hand-held heights \cite{Tedesco-Oliveira2020}. One of the employed models was a two-stage Faster R-CNN \cite{Ren2017}, which first proposes areas of interest and then identifies target objects from the areas. They also employed a CNN-based Single Shot Multibox Detection (SSD)\cite{Liu2016} algorithm designed for recognition of multiple objects from images. Last employed was a lighter version of the SSD algorithm optimized for mobile devices, MobileNetV2 \cite{Sandler2018}. The Faster R-CNN architecture performed the best, having average recall of 0.66 and average precision of 0.59. Using spatial models as automatic boll counters, a linear regression model was trained to predict yield from automatically acquired image data. The yield prediction model utilizing CNN's outputs attained 17.86 \% mean absolute percentage error (MAPE).

Yang et al. developed a CNN acrhitecture to separately utilize RGB and vegetation indices derived from multispectral data for predicting rice grain yield and ripening stages from high-resolution UAV-based images \cite{Yang2019}. For the RGB data, the CNN consisted of five distinct convolutional layers. The CNN using vegetation indices had three convolutional layers. Their approach to yield estimation was to transform the regression problem to a classification problem by assigning a class label to a distinct yield range. While they report fluctuations in performance, assigning the cause to the variability in the input data, they report their best model attained 20.4 \% MAPE and 0.585 for the coefficient of determination (R$^2$).

Kang et al. evaluate several machine learning and deep learning algorithms for maize yield prediction in the US with various data aggregated to county scale \cite{Kang2020}. They utilized various low-resolution spatial data sources in addition to governmental and institutional sources for the environment. The number of input variables was between 58 and 891 depending on the experimental variable selection scheme. While a CNN was utilized, they used it for tabular data, performing 1D convolutions. With tabular data, the CNN achieved 10.1 \% MAPE, while the best performing model, a gradient-boosted decision tree called XGBoost \cite{Chen2016}, achieved 9.1 \% MAPE. Regarding CNN's performance, the authors acknowledge that the architecture is designed to be used with spatial data while their data were non-spatial, albeit containing data from spatial sources pre-aggregation.


\subsection{Long short-term memory networks}
\label{subsec:lstm-review}

The Long Short-Term Memory (LSTM) networks, originally introduced in \cite{Hochreiter1997}, have been widely utilized in sequence modeling tasks \cite{Schmidhuber2014}. LSTMs belong to the deep learning architecture family of recurrent neural networks (RNN). LSTM generally operates with vector-like inputs, which include tabular data and vector outputs from other models. There are two general concepts to the LSTM that help it in learning temporal features from the data. The first is the concept of memory, introduced as the cell state. The other is the concept of gates, effectively trainable FC layers, manipulating this cell state in response to the new inputs from the data and past outputs of the model. To handle sequences of data, the model loops over the sequences altering its cell ($C$) and hidden ($H$) states in the process using the combination of learned parameters in the gates and non-linear activations when combining the gate outputs. LSTMs can also be employed in bidirectional and stacked form. Bidirectional LSTMs train an additional model in comparison to the unidirectional LSTM. One LSTM reads the input from start of the sequence to end ($t_0 \to t_n$), while the other reads the input from end to start ($t_n \to t_0$). The outputs of these two parallel models are then combined as a final sequence of temporal features \cite{Schuster1997}. When LSTMs are stacked, the first LSTM operates on the input sequence and subsequent LSTMs operate on sequences of feature vectors produced by preceding models. Bidirectionality helps the model learn features from both sides of input sequences, while~stacking helps in learning higher level temporal features \cite{Graves2013}. 

Jiang et al. developed a phenology-based LSTM for estimating corn yields in the US at county scale \cite{Jiang2020}. Using phenological data derived from remote sensing, crop information, meteorological and topographical sources, they aggregated tabular data to predict county-wise corn yields. The data was temporal, consisting of five time steps corresponding to distinct maize growth stages during the growing season. To predict the corn yields, they developed a stacked LSTM architecture with two layers. They observed that with longer sequences the LSTM model achieved better results in predicting the crop yield, rising from 0.45 R$^2$ with single year of observations to 0.76 R$^2$ with ten years of observations. Inversely, the RMSE decreased from 1450 kg/ha to 870 kg/ha using one and ten years of observations, respectively. Best results were achieved with multiple years of training data, using 10 preceding years of data to predict the 11th year. 

Kang et al. also evaluated the effectivity of an LSTM in their assessment of machine learning methods for maize yield prediction in the US \cite{Kang2020}. The outline of the study is described in the subsection~\ref{subsec:cnn-review}. With the sequential LSTM model, they report 9.1 \% MAPE and approximately 15.0 bushels per acre (bu/ac) RMSE at best. As the data of the study was processed to be tabular, the sequential model was, at best, on par with the generally best performing model, the XGBoost. The authors however note that the overall performance of the LSTM was only slightly better than what the CNN attained.

Lin et al. utilized weekly aggregates of meterological factors to predict crop yield anomalies with a LSTM-based model \cite{Lin2020}. Their LSTM architecture consisted of three stacked LSTMs, followed by an attention mechanism. As the study area, the US Corn Belt region, is vast, the authors have divided the inputs to spatially distinct regions. Corn yield estimates are generated separately for each region in the final FC layers of the model. The LSTM-based model attained 820 kg/ha RMSE and 0.76 R$^2$ score. The authors also trained two traditional machine learning models, a random forest and a lasso regression model. Their respective performance metrics were 1050 kg/ha RMSE (0.60 R$^2$) and 1140 kg/ha RMSE (0.53 R$^2$).

Schwalbert et al. studied the use of LSTMs in satellite data based soybean yield estimation in southern Brazil \cite{Schwalbert2020}. They utilized data from multiple sources, including low-resolution MODIS satellites, weather data and soybean yield information. Data was acquired for multiple years, from 2002 to 2016. The temporally sequential data was arranged to tabular form, aggregated according to municipalities by averaging. Time step between samples in a sequence was 8 days with sequence start at mid-October. They trained three models in total: an LSTM and two benchmark models, ordinary least squares (OLS) linear regression and random forest. As input sequences were grown longer by shifting the sequence end from January 16 to March 5, the LSTM outperformed both baseline models with the best performance at 320 kg/ha RMSE. However, with shortest input sequence lengths both of the baseline models exhibited better performance. With the shortest sequence, the OLS model attained 530 kg/ha RMSE and the random forest 570 kg/ha RMSE, while the LSTM achieved 680 kg/ha RMSE. The range of observed soybean yields was from 200 kg/ha to 4200 kg/ha.


\subsection{Hybrid CNN-LSTM}
\label{subsec:cnn-lstm-review}

Due to the spatial nature of remote sensing data closely related to the task of crop yield estimation, the LSTMs (and its variants) are often coupled with spatial feature extracting CNNs. The hybrid CNN-LSTM is a composite model consisting of a spatial feature extractor or transformer, i.e., a pretrained CNN, and a temporal model, the LSTM \cite{Sainath2015}. The ability to perform temporal modelling with spatial data is often necessary with, for example, multitemporal remote sensing data. The general idea is to both gain the ability to utilize spatial data and perform sequential modeling with LSTM networks. Instead of feeding the final outputs of a CNN to an FC layer for regression or classification purposes, the CNN output is fed as an input to a sequential LSTM model. The final regression or classification result is produced from the features outputted by the LSTM.

Khaki et al. built and trained a hybrid CNN-LSTM model to predict corn and soybean yields in the US Corn Belt area \cite{Khaki2020}. In their model the spatial inputs, namely soil and weather data at 1 km/px resolution, were first processed by CNNs to extract vectors of high-level spatial features. These features were then fed to the LSTM alongside management and previous year's yield data. They used yearly data from 1980 to 2015 to train the models. The model attained yield prediction average correlation coefficients of 87.3 \% and 86.2 \% for corn and soybean, respectively. Comparing to the benchmark models, the results were, on average, 17.4 and 25.9 \%-units higher for corn and soybean yield prediction, respectively again. The authors observe that the CNN-LSTM model is able to efficiently perform feature selection from large feature space. They also observe that the model generalizes well to unseen samples.

Yaramasu et al. utilized a CNN-LSTM architecture to extract spatiotemporal features from nationally generated crop type maps in the US \cite{Yaramasu2020}. The extracted features were then fed to a decoder to reconstruct an estimate crop type map for an upcoming year. The spatial feature extracting CNN of the spatiotemporal encoder was a pre-trained VGG11 \cite{Simonyan2015}. Their input data consisted of medium resolution, 30 m/px, spatial crop type classification maps spanning the US continent. Using year as the time step, they trained the model to predict a crop map for a 512 $\times$ 512 px or 236 km$^2$ area based on crop type changes in the preceding years. They achieved average overall accuracy of 77 \%.

Yue et al. also developed spatiotemporal encoder-decoder architectures to predict progressions of meterological factors, such as daily precipitation \cite{Yue2020}. Encoder-decoder architecture first learns to compress the data and the feature-wise interactions to a high-level vector or matrix representation, and the decoder then is used to recreate the desired target from this encoded output \cite{Vincent2008}. The encoder and decoder are jointly trained to facilitate extraction of robust high-level features. Daily data was utilized from a year to predict the progression of distinct meterological variables for the year following the input data. These predictions were then further utilized to estimate maize growth stages. While the focus of their study was a convolutional LSTM based encoder-decoder architecture, they also trained a CNN-LSTM based encoder-decoder for comparative purposes. Their input data consisted of tabular meteorological data, meaning the convolutional operations were 1D. With other models also trained, of the encoder-decoders the CNN-LSTM was able to surpass the best performing convolutional LSTM in daily cumulative precipitation prediction with MAE of 3.33 mm against 3.88 mm, respectively.

Rustowicz et al. built a multisource CNN-LSTM architecture to classify crop types in Ghana, South Sudan and Germany from satellite data \cite{Rustowicz2019}. Using high-resolution PlanetScope and medium-resolution Sentinel-1 and Sentinel-2 satellite data, they build an architecture capable of utilizing time series of spatial data from each satellite source. The model consist, thus, of three CNN-LSTMs for each input source. The outputs of these models are then concatenated to generate the final model output, crop type classification result. The authors also built and trained a spatiotemporal 3D-CNN model, discussed in Section~\ref{subsec:3d-cnn-review}. A random forest model was trained as a baseline model. The CNN-LSTM performed the best with majority of crop types in Germany and Ghana, attaining 95.8 \% and 59.9 \% respective overall accuracies. For South Sudan, the baseline RF performed the best with majority of crops with average accuracy of 88.7 \% while the CNN-LSTM model attained 82.6 \% accuracy.

Sun et al. designed and trained a hybrid CNN-LSTM architecture to predict county-level soybean yields in the US \cite{Sun2019}. The input data used was multiyear and multisource, consisting of data from MODIS satellite system, weather information, crop yield statistics and county boundary information. A sequence of yearly spatial inputs consisted of 34 time steps with 8 day span between steps. The CNN extracts spatial features from each spatial input of the whole input sequence. The sequence of spatial inputs is thus transformed to a sequence of high-level feature vectors. The sequence of vectors is then the input for the LSTM. In addition to using full sequences, the authors examine the model's prediction performance with shorter sequences from the beginning of a season. The CNN-LSTM attained 0.78 R$^2$ with full sequence and 0.74 R$^2$ using ten 8-day time steps from the beginning of the season.


\subsection{Convolutional LSTM}
\label{subsec:conv-lstm-review}

Convolutional LSTM \cite{Shi2015a} is a model combining the features of convolutional and sequential models into a single architecture, using convolutional layers (convolution with pooling etc.) as the LSTM's gate functions. This makes it possible to feed the sequential model the spatial data directly. Akin to how convolutional networks learn, the gates learn to utilize the convolutional kernels to provide the best set of spatial features when building and modifying the cell state $C$. Thus, contrary to the CNN-LSTM, no pre-extraction of spatial features is required. While LSTM has been predominantly utilized in agriculture related sequential modelling tasks \cite{VanKlompenburg2020,Kamilaris2018a}, convolutional recurrent architectures have also been employed with a gated recurrent unit (GRU) \cite{Cho2014}. The general difference between LSTM and GRU is the number of gates and, thus, trainable parameters. Convolutional layers are present in both with their convolutional recurrent variants.

Yue et al. studied of maize growth stage prediction with encoder-decoder model architectures and meterological data, focusing on a convolutional LSTM based model \cite{Yue2020}. The setting of the study is described in Section~\ref{subsec:cnn-lstm-review}. They authors decided to utilize 1D convolutions in the convolutional LSTM's input gate functions to extract features depicting complex interactions within the meteorological data. The authors report the convolutional LSTM encoder-decoder architecture performing the best in majority of meteorological factor estimation cases: 2.60 $^o$C MAE and 3.46 $^o$C RMSE for average temperature, 3.88 $^o$C MAE and 10.50 $^o$C RMSE for daily cumulative precipitation and 3.45 $^o$C MAE and 4.17 $^o$C RMSE for daily sunshine duration. The convolutional LSTM achieved the closest average predicted-to-real ratio of 0.91. The next best average ratio of 0.75 was attained by a gated recurrent unit (GRU) based model.

Ru{\ss}wurm and K{\"{o}}rner sought to utilize the temporal nature of spatial earth observation satellite data in pixel-wise crop type multi-class classification by designing bidirectional convolutional recurrent models \cite{Russwurm2018}. Compared models utilized either LSTM or GRU as the recurrent model. Using Sentinel-2 data interpolated to 10 m/px, they gathered data from a 4300 km$^2$ area in southern Germany, subdividing it to smaller 15 km$^2$ areas. Time was encoded to the data by introducing the information of the year and day-of-year of the satellite fly-over. The authors observed that the performance of both models were so similar, that they reported only the performance of the GRU-based convolutional recurrent model. They report the model attaining a 89.6 \% average classification with data from 2016 and 2017. They conclude that their model is able to attain state-of-the-art accuracy without common satellite data preprocessing, such as atmospheric correction or cloud identification.

Russwurm and K{\"{o}}rner further investigate the robustness of a single layer convolutional LSTM to clouds in satellite time series data \cite{Russwurm2018b}. The data is from the same area and overall similar to \cite{Russwurm2018}. Training the model with similar data, they performed ablation experiments with varying degrees of cloud coverage. They observe that the convolutional LSTM is indifferent towards occasional cloud coverage. With images sorted according to their cloudiness from no clouds to up to half-cloudy, the model was with all cases capable at achieving between 90 \% and 93 \% accuracy. The accuracy was determined with regards to crop type classification. The authors conclude that clouds are effectively noise in temporal data and the convolutional LSTM is able to account for that.

Ienco et al. develop a multisource CNN and convolutional GRU based model to classify land cover from multitemporal Sentinel-1 and Sentinel-2 data \cite{Ienco2019}. The model consists of two identical architectures for distinct satellite sources. An architecture contains a CNN and a convolutional GRU, both producing a high-level feature vector of set length. The vectors are concatenated and then fed to a FC layer for classification. The satellite time series data was acquired of two distinct sites in Reunion Islands and Burkina Faso. Using only the convolutional GRU models, they attained 88.2 \% accuracy on pixel-wise land type classification. Comparatively, using the CNN models only produced 87.7 \% accuracy. The full model attained 89.9 \% accuracy. 

Liu et al. utilized a bidirectional convolutional LSTM with hyperspectral data to perform spectral-spatial land cover classification \cite{Liu2017}. Using three distinct satellite-based hyperspectral image data sets, the authors utilize the sequential nature of the convolutional LSTM to learn inter-spectral high-level spatial features from the input data. They compared the model to several other architectures, including CNN, LSTM, 3D-CNN, and CNN-LSTM. Best results on 16-class land cover classification were achieved with bidirectional convolutional LSTM, 3D-CNN and CNN-LSTM with respective average accuracies being 97.1 \%, 95.2 \% and 94.5 \% over all data sets.


\subsection{Three-dimensional CNN}
\label{subsec:3d-cnn-review}

As initially reported by \cite{Tran2015}, 3D-CNNs performed remarkably well in modeling tasks involving spatiotemporal data. Being CNNs, the 3D-CNNs utilize all same architectural features as more commonly used convolutional models. What's different is their use of convolution in the depth dimension, searching for robust features across sequences of input data in addition to spatial features extracted from the individual images. The sequential nature of input data is not limited to time, but can also be, for example, hyperspectral multi-layer point-in-time data with the aim of finding high-level inter-channel features \cite{Li2017}.

Barbosa et al. developed and trained multiple models to predict crop yield from spatially formatted crop management data \cite{Barbosa2020}. The outline of the study has been elaborated in Section~\ref{subsec:cnn-review}. One of the models was based on 3D-CNN architecture, consisting of a single 3D convolutional layer coupled with two FC layers. They utilized the 3D-CNN to extract inter-channel high-level features from the inputs. The 3D-CNN model was observed to perform on-par with majority of other CNN-based solutions, attaining 0.73 RMSE, which translates to 1190 kg/ha when unscaled.

Terliksiz and Altylar studied the use of a 3D-CNN architecture to predict soybean yields from spatiotemporal data at county-scale in the US \cite{Terliksiz2019}. The input data was acquired annually from 2003 to 2016 from the spatially low-resolution MODIS satellites at 8-day intervals between each data sample. A single sequence consisted of 24 subframes cropped from the initial, larger area. The model implemented by the authors consists of two initial 2D CNN layers, followed by six 3D convolutions and two FC layers for single value prediction. Their model attained an average 4.42 bu/ac RMSE with various land cover ratio ablations in input frames. Comparing to other similar studies, their result is, at minimum, 0.90 bu/ac RMSE lower. They authors discuss, however, that the use of within-county smaller frames to predict a county-wide average yield can be misleading.

In their study of crop type classfication in Germany, South Sudan and Ghana, Rustowicz et al. also built and trained a 3D-CNN encoder-decoder architecture to classify pixels in sequences of frames extracted from satellite data \cite{Rustowicz2019}. The study is described in Section~\ref{subsec:cnn-lstm-review}. The 3D-CNN model performed close to the CNN-LSTM model, attaining 95.2 \%, 60.9 \% and 85.3 \% overall accuracies with Germany, Ghana and South Sudan data sets, respectively. While CNN-LSTM performed better with Germany by 0.6 \%-units, the 3D-CNN had better overall accuracy with Ghana and South Sudan by 1.0 \%-units and 2.7 \%-units, respectively. With ablation studies, the best setting with 3D-CNN outperforms the best CNN-LSTM setting 1.3 \%-units with South Sudan data set in terms of accuracy, while CNN-LSTM attains 2.2 \%-units higher accuracy with Ghana data set. 

Ji et al. developed a 3D-CNN model to perform crop type classification with spatiotemporal data \cite{Ji2018}. They use data from 4 m/px resolution Gaofen 1 and 15 m/px Gaofen 2 satellite systems, acquired for several months from 2014 to 2016. The model constisted of three 3D convolution layers followed by two FC layers. The 3D-CNN outperforms other methods in pixel-wise classification, including a CNN and several traditional machine learning methods. The average overall accuracy of the model is 94.9 \%. Two closest contender models, a CNN and a support vector machine (SVM), attain 91.8 \% and 91.9 \% average overall accuracies, respectively. 

Li, Zhang and Shen studied the use of 3D-CNN models in spectral-spatial land cover classification with hyperspectral data \cite{Li2017}. The authors use three hyperspectral data sets from Italy, Botswana and India. A two-layer 3D-CNN architecturethe is built and trained to perform pixel-wise classification of remotely sensed scenes. The model is compared against models developed in other studies and similar settings, including a stacked autoencoder, deep belief network and a CNN. The 3D-CNN attained 99.3 \% overall accuracy. With notable differences ($>$2 \%-units) in prediction accuracies only observed with the Indian data set, the authors notice the 3D-CNN having the lowest misclassification ratio out of the compared models. While spatial model were observed to perform the best overall, the authors attribute the best performance of the 3D-CNN to its ability to learn salient inter-spectral features from the input data.